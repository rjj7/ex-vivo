{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel.streamlines import save as save_trk\n",
    "from nibabel.streamlines import Tractogram\n",
    "import numpy as np\n",
    "\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import (\n",
    "    fetch_stanford_hardi, read_stanford_hardi, get_sphere)\n",
    "from dipy.direction import peaks_from_model\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.reconst.csdeconv import (\n",
    "    ConstrainedSphericalDeconvModel,auto_response)\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.tracking.local import (\n",
    "    LocalTracking, ThresholdTissueClassifier)\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.utils import random_seeds_from_mask\n",
    "from dipy.viz import actor, window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Diffusion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (140, 140, 96, 69)\n",
      "B-Values: \n",
      "[    0.     0.     0.     0.     0.  1000.  1000.  1000.  1000.  1000.\n",
      "  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.\n",
      "  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.\n",
      "  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.\n",
      "  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.\n",
      "  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.\n",
      "  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.  1000.]\n"
     ]
    }
   ],
   "source": [
    "dwi_img_filename = (\"dwi.nii.gz\")\n",
    "dwi_img = nib.load(dwi_img_filename)\n",
    "dwi = dwi_img.get_data()\n",
    "print(\"Data Shape: \" + str(dwi.shape))\n",
    "\n",
    "fbval=(\"dwi.bval\")\n",
    "fbvec = (\"dwi.bvec\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab = gradient_table(bvals,bvecs)\n",
    "print(\"B-Values: \\n\" + str(gtab.bvals))\n",
    "\n",
    "recompute=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Brain Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brain_mask_filename = \"brain_mask.nii.gz\"\n",
    "if path.exists(brain_mask_filename) and not recompute:\n",
    "    brain_mask_img = nib.load(brain_mask_filename).get_data()\n",
    "else:\n",
    "    recompute = True\n",
    "    _, brain_mask_img = median_otsu(dwi, 4, 1)\n",
    "    save_nifti(brain_mask_filename, brain_mask_img.astype(\"uint8\"),\n",
    "               dwi_img.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa_filename = \"fa.nii.gz\"\n",
    "if path.exists(fa_filename) and not recompute:\n",
    "    fa = nib.load(fa_filename).get_data()\n",
    "else:\n",
    "    recompute = True\n",
    "    tensor_model = TensorModel(gtab, fit_method='WLS')\n",
    "    tensor_fit = tensor_model.fit(dwi, brain_mask_img)\n",
    "    fa = tensor_fit.fa\n",
    "    save_nifti(fa_filename, fa, dwi_img.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "csd_peaks_filename = \"csd_peaks.pkl\"\n",
    "if path.exists(csd_peaks_filename) and not recompute:\n",
    "    pkl_file = open(csd_peaks_filename, \"rb\")\n",
    "    csd_peaks = pickle.load(pkl_file)\n",
    "    pkl_file.close\n",
    "else:\n",
    "    recompute = True\n",
    "    response, ratio = auto_response(\n",
    "        gtab, dwi, roi_radius=10, fa_thr=0.7)\n",
    "    csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "    sphere = get_sphere('symmetric724')\n",
    "    csd_peaks = peaks_from_model(\n",
    "        model=csd_model, data=dwi, sphere=sphere, mask=brain_mask_img,\n",
    "        relative_peak_threshold=.5, min_separation_angle=25,\n",
    "        parallel=True)\n",
    "    pkl_file = open(csd_peaks_filename, \"wb\")\n",
    "    pickle.dump(csd_peaks, pkl_file)\n",
    "    pkl_file.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSD Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauvin/workspace/dipy/dipy/viz/colormap.py:233: RuntimeWarning: invalid value encountered in true_divide\n",
      "  orient = np.abs(orient / np.linalg.norm(orient))\n"
     ]
    }
   ],
   "source": [
    "interactive = True\n",
    "ren = window.Renderer()\n",
    "ren.add(actor.peak_slicer(\n",
    "    csd_peaks.peak_dirs, csd_peaks.peak_values, colors=None))\n",
    "\n",
    "if interactive:\n",
    "    window.show(ren, size=(900, 900))\n",
    "else:\n",
    "    window.record(\n",
    "        ren, out_path='csd_direction_field.png', size=(900, 900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of streamlines: 88155\n"
     ]
    }
   ],
   "source": [
    "tractogram_filename = \"det_csd_streamlines.trk\"\n",
    "if path.exists(tractogram_filename) and not recompute:\n",
    "    streamlines = nib.streamlines.load(tractogram_filename).streamlines\n",
    "else:\n",
    "    tissue_classifier = ThresholdTissueClassifier(fa, 0.1)\n",
    "    seeds = random_seeds_from_mask(fa > 0.5, seeds_count=1)\n",
    "    streamline_generator = LocalTracking(\n",
    "        csd_peaks, tissue_classifier, seeds, affine=np.eye(4),\n",
    "        step_size=0.5)\n",
    "\n",
    "    streamlines = Streamlines(streamline_generator)\n",
    "    save_trk(\n",
    "        Tractogram(streamlines, affine_to_rasmm=dwi_img.affine),\n",
    "        tractogram_filename)\n",
    "print(\"Number of streamlines: \" + str(len(streamlines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlines Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauvin/workspace/dipy/dipy/viz/colormap.py:233: RuntimeWarning: invalid value encountered in true_divide\n",
      "  orient = np.abs(orient / np.linalg.norm(orient))\n"
     ]
    }
   ],
   "source": [
    "ren.clear()\n",
    "ren.add(actor.line(streamlines))\n",
    "\n",
    "if interactive:\n",
    "    window.show(ren, size=(900, 900))\n",
    "else:\n",
    "    print('Saving illustration as det_streamlines.png')\n",
    "    window.record(ren, out_path='det_streamlines.png', size=(900, 900))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
