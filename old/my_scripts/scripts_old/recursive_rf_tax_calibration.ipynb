{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from nibabel.streamlines import save as save_trk\n",
    "from nibabel.streamlines import Tractogram\n",
    "from os import path\n",
    "from dipy.tracking.local import ParticleFilteringTracking\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere, Sphere, HemiSphere\n",
    "from dipy.direction import (peaks_from_model, ProbabilisticDirectionGetter)\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.io.streamline import save_trk, load_trk\n",
    "from dipy.reconst.peaks import reshape_peaks_for_visualization\n",
    "from dipy.reconst.dti import TensorModel, fractional_anisotropy, mean_diffusivity\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,auto_response, recursive_response, AxSymShResponse)\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.tracking.local import (LocalTracking, ThresholdTissueClassifier, ActTissueClassifier, CmcTissueClassifier)\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.utils import random_seeds_from_mask, move_streamlines\n",
    "from dipy.viz import actor, window\n",
    "from dipy.tracking.utils import target, density_map\n",
    "from dipy.reconst.shm import lazy_index, real_sph_harm\n",
    "from dipy.core.geometry import vec2vec_rotmat, cart2sphere\n",
    "from dipy.tracking import distances\n",
    "from dipy.core.ndindex import ndindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/space/hemera/1/users/cmaffei/data_nancy/kancon03/')\n",
    "wd = '/space/hemera/1/users/cmaffei/data_nancy/kancon03/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (140, 140, 78, 272)\n",
      "Voxel Size: (1.8, 1.8, 1.8000001)\n",
      "Mask Shape: (140, 140, 78)\n"
     ]
    }
   ],
   "source": [
    "# Import DWI data, bvec, bval, and binary mask\n",
    "fimg =  ('/space/neptune/1/users/srf29/diffusion/kanwishercon/db/vols_dti/mgh/kancon03/dti/data.nii.gz')\n",
    "img = nib.load(fimg)\n",
    "data = img.get_data()\n",
    "print(\"Data Shape: \" + str(data.shape))\n",
    "affine = img.affine #no need to store the affine tho. \n",
    "\n",
    "#Bval and bvec file information import\n",
    "fbval= ('bvals')\n",
    "fbvec = (\"bvecs\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab = gradient_table(bvals,bvecs)\n",
    "#Read the voxel size from the image header.\n",
    "voxel_size = img.header.get_zooms()[:3]\n",
    "print ('Voxel Size: ' + str(voxel_size))\n",
    "\n",
    "#importing binary mask\n",
    "mask=(\"/space/neptune/1/users/srf29/diffusion/kanwishercon/db/vols_dti/mgh/kancon03/dti/nodif_brain_mask.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "mask = img.get_data()\n",
    "#print('mask.shape (%d, %d, %d)' % mask.shape)\n",
    "print(\"Mask Shape: \" + str(mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import DWI data, bvec, bval, and binary mask\n",
    "fimg =  ('1k/mgh_1015/data_corr.nii.gz')\n",
    "img = nib.load(fimg)\n",
    "data_1k = img.get_data()\n",
    "print(\"Data Shape: \" + str(data_1k.shape))\n",
    "affine = img.affine #no need to store the affine tho. \n",
    "\n",
    "#Bval and bvec file information import\n",
    "fbval= ('1k/mgh_1015/bvals')\n",
    "fbvec = (\"1k/mgh_1015/bvecs\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab_1k = gradient_table(bvals,bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_small=data[50:90,65:75,50:80]\n",
    "data_1k_small=data_1k[50:90,65:75,50:80]\n",
    "mask_small=mask[50:90,65:75,50:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace = 0.0021\n",
    "fa = 0.1\n",
    "peak_thr = 0.08\n",
    "convergence = 0.001\n",
    "S0 = 1.\n",
    "sh_order = 8\n",
    "sphere = get_sphere('symmetric642')\n",
    "min_sep_angle = 25\n",
    "parallel = True\n",
    "nbr_processes = 4\n",
    "iter = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing binary mask\n",
    "wm_mask=(\"t12fa_pve_2_res.nii.gz\")\n",
    "img = nib.load(wm_mask)\n",
    "wm_mask = img.get_data()\n",
    "wm_mask=wm_mask>0.8\n",
    "nib.save(nib.Nifti1Image(wm_mask.astype('float32'), img.affine, img.header), os.path.join(wd, 'wm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda1 = (trace / 3.) * (1 + 2 * fa / (3 - 2 * fa ** 2) ** (1 / 2.))\n",
    "lambda2 = (trace / 3.) * (1 - fa / (3 - 2 * fa ** 2) ** (1 / 2.))\n",
    "evals = np.array([lambda1, lambda2, lambda2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show initial RF\n",
    "\n",
    "res_obj = (evals, S0)\n",
    "\n",
    "interactive = True\n",
    "\n",
    "ren = window.Renderer()\n",
    "evals = res_obj[0]\n",
    "evecs = np.array([[0, 1, 0], [0, 0, 1], [1, 0, 0]]).T\n",
    "\n",
    "sphere = get_sphere('symmetric724')\n",
    "from dipy.sims.voxel import single_tensor_odf\n",
    "response_odf = single_tensor_odf(sphere.vertices, evals, evecs)\n",
    "# transform our data from 1D to 4D\n",
    "response_odf = response_odf[None, None, None, :]\n",
    "response_actor = actor.odf_slicer(response_odf, sphere=sphere, colormap='plasma')\n",
    "ren.add(response_actor)\n",
    "\n",
    "window.record(ren, out_path='fat_response.png', size=(200, 200))\n",
    "if interactive:\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fa7d8e1457a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# response=res_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcsd_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstrainedSphericalDeconvModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msphere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sphere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'symmetric724'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m csd_peaks = peaks_from_model(model=csd_model,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "# response=res_obj\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "sphere = get_sphere('symmetric724')\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=data_small,\n",
    "                             sphere=sphere,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25,\n",
    "                             mask=mask_small, return_odf=True, return_sh=True)\n",
    "ren = window.Renderer()\n",
    "interactive = True\n",
    "fodf_spheres = actor.odf_slicer(csd_peaks.odf, sphere=sphere, scale=0.6, colormap='plasma')\n",
    "fodf_spheres.display_extent(0, 40, 5, 5, 0, 30)\n",
    "ren.set_camera(position=(0, 10, 0))\n",
    "ren.add(fodf_spheres)\n",
    "if interactive:\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of initial voxels is(74934, 272)\n",
      "Iteration: 0\n",
      "shape of vals is: (74934, 5)\n",
      "single mask shape is(74934,)\n",
      "data shape is(68432, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 193.11474977   60.28688142   23.02107749   10.19402128    2.25861309]\n",
      "Iteration: 1\n",
      "shape of vals is: (68432, 5)\n",
      "single mask shape is(68432,)\n",
      "data shape is(17307, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 0.0229868   0.36261189  0.60472651  0.81075337  1.07272633]\n",
      "Iteration: 2\n",
      "shape of vals is: (17307, 5)\n",
      "single mask shape is(17307,)\n",
      "data shape is(7298, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 0.02497905  0.1221003   0.17031242  0.21687586  0.24842614]\n",
      "Iteration: 3\n",
      "shape of vals is: (7298, 5)\n",
      "single mask shape is(7298,)\n",
      "data shape is(4934, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 0.01319517  0.0462794   0.06079106  0.07581044  0.08111277]\n",
      "Iteration: 4\n",
      "shape of vals is: (4934, 5)\n",
      "single mask shape is(4934,)\n",
      "data shape is(4234, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 0.00625778  0.01884595  0.02349078  0.02826824  0.03367211]\n",
      "Iteration: 5\n",
      "shape of vals is: (4234, 5)\n",
      "single mask shape is(4234,)\n",
      "data shape is(3971, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 0.00231002  0.00628202  0.00804655  0.00978169  0.01280992]\n",
      "Iteration: 6\n",
      "shape of vals is: (3971, 5)\n",
      "single mask shape is(3971,)\n",
      "data shape is(3893, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 0.00038858  0.00194167  0.00250718  0.00336224  0.00416822]\n",
      "Iteration: 7\n",
      "shape of vals is: (3893, 5)\n",
      "single mask shape is(3893,)\n",
      "data shape is(3857, 272)\n",
      "updating response\n",
      "visualize response\n",
      "Saving illustration as csd_recursive_response.png\n",
      "checking convergence\n",
      "change in response is[ 0.00027324  0.00123126  0.00209116  0.00275269  0.00309281]\n"
     ]
    }
   ],
   "source": [
    "n = np.arange(0, sh_order + 1, 2)\n",
    "where_dwi = lazy_index(~gtab.b0s_mask)\n",
    "response_p = np.ones(len(n))\n",
    "res_obj=(evals, S0)\n",
    "r_sh_all=None\n",
    "shape = data.shape[:-1]\n",
    "data_rc = data[wm_mask]\n",
    "print'The number of initial voxels is'+str(data_rc.shape)\n",
    "\n",
    "indices = zip(*np.where(wm_mask==True))\n",
    "    \n",
    "for _ in range(iter):\n",
    "    \n",
    "    sf_voxels = np.zeros(shape)\n",
    "    for idx in indices:\n",
    "            sf_voxels[idx]=1\n",
    "    nib.save(nib.Nifti1Image(sf_voxels.astype('float32'), img.affine, img.header), \n",
    "             os.path.join(wd, str(_)+'sf_voxels.nii.gz')) \n",
    "\n",
    "    \n",
    "    print 'Iteration: '+str((_))\n",
    "    r_sh_all = np.zeros(len(n))\n",
    "    csd_model = ConstrainedSphericalDeconvModel(gtab, res_obj, sh_order=sh_order)\n",
    "    csd_peaks = peaks_from_model(model=csd_model, data=data_rc, sphere=sphere,\n",
    "                                 relative_peak_threshold=peak_thr, \n",
    "                                 min_separation_angle=min_sep_angle, parallel=False)\n",
    "\n",
    "    #single peaks mask\n",
    "    dirs = csd_peaks.peak_dirs\n",
    "    vals = csd_peaks.peak_values\n",
    "    print'shape of vals is: '+str(vals.shape)\n",
    "    single_peak_mask = (vals[:, 1] / vals[:, 0]) < peak_thr\n",
    "    print 'single mask shape is'+str(single_peak_mask.shape)\n",
    "    data_rc = data_rc[single_peak_mask]\n",
    "    print'data shape is'+str(data_rc.shape)\n",
    "    dirs = dirs[single_peak_mask]\n",
    "    \n",
    "    new_indices=[]\n",
    "    for i in range(len(indices)):\n",
    "        if single_peak_mask[i]==True:\n",
    "            new_indices.append(indices[i])\n",
    "    indices = new_indices\n",
    "    \n",
    "    #reorient diffusion signal so thet the estimated fibers lies along z\n",
    "    for num_vox in range(data_rc.shape[0]):\n",
    "        rotmat = vec2vec_rotmat(dirs[num_vox, 0], np.array([0, 0, 1]))\n",
    "        rot_gradients = np.dot(rotmat, gtab.gradients.T).T\n",
    "        x, y, z = rot_gradients[where_dwi].T\n",
    "        r, theta, phi = cart2sphere(x, y, z)\n",
    "        B_dwi = real_sph_harm(0, n, theta[:, None], phi[:, None])\n",
    "        r_sh_all += np.linalg.lstsq(B_dwi, data_rc[num_vox, where_dwi], rcond=-1)[0]\n",
    "    \n",
    "    print('updating response')\n",
    "    response = r_sh_all / data_rc.shape[0]\n",
    "    res_obj = AxSymShResponse(data_rc[:, gtab.b0s_mask].mean(), response)\n",
    " \n",
    "    print('visualize response')\n",
    "    interactive = False\n",
    "    sphere = get_sphere('symmetric724')\n",
    "    response_signal = res_obj.on_sphere(sphere)\n",
    "    # transform our data from 1D to 4D\n",
    "    response_signal = response_signal[None, None, None, :]\n",
    "    response_actor = actor.odf_slicer(response_signal, sphere=sphere, colormap='plasma')\n",
    "    ren = window.Renderer()\n",
    "    ren.add(response_actor)\n",
    "    print('Saving illustration as csd_recursive_response.png')\n",
    "    window.record(ren, out_path=str(_)+'rf.png', size=(200, 200))\n",
    "    if interactive:\n",
    "        window.show(ren)\n",
    "\n",
    "    print('checking convergence')\n",
    "    change = abs((response_p - response) / response_p)\n",
    "    print'change in response is'+str(change)\n",
    "    if all(change < convergence):\n",
    "        break\n",
    "        \n",
    "    response_p = response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.52063379, -32.7245135 ,  23.19480477, -14.85681182,   8.54864693])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_obj = AxSymShResponse(data_rc[:, gtab.b0s_mask].mean(), response)\n",
    "\n",
    "#check the shape of the signal of the response function, which should be like a pancake:\n",
    "sphere = get_sphere('symmetric724')\n",
    "response_signal = res_obj.on_sphere(sphere)\n",
    "# transform our data from 1D to 4D\n",
    "response_signal = response_signal[None, None, None, :]\n",
    "response_actor = actor.odf_slicer(\n",
    "    response_signal, sphere=sphere, colormap='plasma')\n",
    "interactive = True\n",
    "ren = window.Renderer()\n",
    "\n",
    "ren.add(response_actor)\n",
    "if interactive:\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, res_obj)\n",
    "sphere = get_sphere('symmetric724')\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=data,\n",
    "                             sphere=sphere,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25,\n",
    "                             mask=mask, return_odf=True, return_sh=True)\n",
    "\n",
    "# save odf\n",
    "nib.save(nib.Nifti1Image(csd_peaks.shm_coeff.astype(np.float32),\n",
    "                                  img.affine, img.header), 'odf_csd_fa02_pr01_fa08.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Enables/disables interactive visualization\n",
    "ren = window.Renderer()\n",
    "interactive = True\n",
    "fodf_spheres = actor.odf_slicer(csd_peaks.odf, sphere=sphere, scale=0.6, norm=False, colormap='plasma')\n",
    "fodf_spheres.display_extent(0, 140, 81, 81, 0, 96)\n",
    "ren.set_camera(position=(0, 10, 0))\n",
    "ren.add(fodf_spheres)\n",
    "\n",
    "# print('Saving illustration as csd_odfs.png')\n",
    "# window.record(ren, out_path='csd_fods.png', size=(600, 600))\n",
    "if interactive:\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:22: DeprecationWarning: get_header method is deprecated.\n",
      "Please use the ``img.header`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n"
     ]
    }
   ],
   "source": [
    "#tractography parameters\n",
    "step_size = 0.75\n",
    "max_angle= 45\n",
    "pmf_thr=0.1\n",
    "seeds_count=5\n",
    "affine=np.eye(4)\n",
    "sphere = get_sphere('symmetric724')\n",
    "from dipy.reconst.shm import sh_to_sf\n",
    "fimg = (\"odf_csd_fa04_pr03_bodycc.nii.gz\")\n",
    "img = nib.load(fimg)\n",
    "odfs = img.get_data()\n",
    "seed_mask=(\"wm_mask_bin.nii.gz\")\n",
    "imgm = nib.load(seed_mask)\n",
    "seed_mask = imgm.get_data()\n",
    "\n",
    "img_pve_gm = nib.load('t12fa_pve_1_res.nii.gz')\n",
    "img_pve_csf = nib.load('t12fa_pve_0_res.nii.gz')\n",
    "img_pve_wm = nib.load('t12fa_pve_2_res.nii.gz')\n",
    "seeds = random_seeds_from_mask(seed_mask, seeds_count=5)\n",
    "from dipy.tracking.local import ParticleFilteringTracking\n",
    "from dipy.tracking.local import CmcTissueClassifier\n",
    "voxel_size = np.average(img_pve_wm.get_header()['pixdim'][1:4])\n",
    "prob_dg = ProbabilisticDirectionGetter.from_shcoeff(odfs, max_angle=45, sphere=sphere)\n",
    "cmc_classifier = CmcTissueClassifier.from_pve(img_pve_wm.get_data(),\n",
    "                                              img_pve_gm.get_data(),\n",
    "                                              img_pve_csf.get_data(),\n",
    "                                              step_size=step_size,\n",
    "                                              average_voxel_size=voxel_size)\n",
    "\n",
    "all_streamlines_act_classifier = LocalTracking(prob_dg,\n",
    "                                               cmc_classifier,\n",
    "                                               seeds, \n",
    "                                               affine=np.eye(4), step_size=0.75,\n",
    "                                               return_all=True)\n",
    "\n",
    "streamlines = Streamlines(all_streamlines_act_classifier)\n",
    "save_trk(\"odf_csd_fa04_pr03_bodycc.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
