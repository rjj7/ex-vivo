{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dipy.reconst.dti as dti\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.reconst.dti import fractional_anisotropy, color_fa, lower_triangular\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.viz import window, actor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (140, 140, 96, 69)\n",
      "mask.shape (140, 140, 96)\n"
     ]
    }
   ],
   "source": [
    "# Import DWI data, bvec, bval, and binary mask\n",
    "fimg = (\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/1000/from_mgh/data.nii.gz\")\n",
    "img = nib.load(fimg)\n",
    "data = img.get_data()\n",
    "print('data.shape (%d, %d, %d, %d)' % data.shape)\n",
    "affine = img.affine #no need to store the affine tho. \n",
    "\n",
    "#Bval and bvec file information import\n",
    "fbval=(\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/1000/from_mgh/bvals\")\n",
    "fbvec = (\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/1000/from_mgh/bvecs\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab = gradient_table(bvals,bvecs)\n",
    "#print(gtab.bvals) #to read the bvals\n",
    "\n",
    "\n",
    "#Read the voxel size from the image header.\n",
    "voxel_size = img.header.get_zooms()[:3]\n",
    "\n",
    "#To import fod?\n",
    "#sh_data = nib.load(args.sh_file).get_data().astype('float64')\n",
    "\n",
    "#importing binary mask\n",
    "mask=(\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/1000/mask_con.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "mask = img.get_data()\n",
    "print('mask.shape (%d, %d, %d)' % mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the tensor model to data\n",
    "tenmodel = dti.TensorModel(gtab)\n",
    "tenfit = tenmodel.fit(data, mask)\n",
    "\n",
    "#Compute dti maps\n",
    "fa = fractional_anisotropy(tenfit.evals)\n",
    "# In the background of the image the fitting will not be accurate there is no signal and possibly we will find FA values\n",
    "# with nans (not a number). We can easily remove these in the following way.\n",
    "# FA[np.isnan(FA)] = 0\n",
    "# fa_img = nib.Nifti1Image(FA.astype(np.float32), img.affine)\n",
    "# nib.save(fa_img, 'tensor_fa.nii.gz')\n",
    "\n",
    "# #We can also compute the colored FA or RGB-map [Pajevic1999]. First, we make sure that the FA is scaled between 0 and 1,\n",
    "# we compute the RGB map and save it.\n",
    "# FA = np.clip(FA, 0, 1)\n",
    "# RGB = color_fa(FA, tenfit.evecs)\n",
    "# nib.save(nib.Nifti1Image(np.array(255 * RGB, 'uint8'), img.affine), 'tensor_rgb.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "FA = np.clip(fa, 0, 1)\n",
    "RGB = color_fa(FA, tenfit.evecs)\n",
    "nib.save(nib.Nifti1Image(np.array(255 * RGB, 'uint8'), img.affine), '/space/hemera/1/users/cmaffei/data_30_05/rgb.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualization\n",
    "\n",
    "sphere = get_sphere('symmetric724')\n",
    "\n",
    "# Enables/disables interactive visualization\n",
    "interactive = True\n",
    "ren = window.Renderer()\n",
    "\n",
    "evals = tenfit.evals[63:64, 57:87, 43:73]\n",
    "evecs = tenfit.evecs[63:64, 57:87, 43:73]\n",
    "\n",
    "# We can color the ellipsoids using the color_fa values that we calculated above.\n",
    "# In this example we additionally normalize the values to increase the contrast.\n",
    "cfa = RGB[13:43, 44:74, 28:29]\n",
    "cfa /= cfa.max()\n",
    "\n",
    "# We can visualize the tensor Orientation Distribution Functions for the same area as we did with the ellipsoids.\n",
    "# We first mask the data\n",
    "# maskdata_cut, mask = median_otsu(data_cut, 3, 1, True,\n",
    "#                                  vol_idx=range(10, 50), dilate=2)\n",
    "# \n",
    "#Axial\n",
    "# index = data.shape[2] // 2\n",
    "# data_cut_z = data [:, :, index:index+1]\n",
    "# tensor_odfs = tenmodel.fit(data_cut_z).odf(sphere)\n",
    "# odf_actor = actor.odf_slicer(tensor_odfs, sphere=sphere, scale=0.5)\n",
    "# odf_actor.display(z=0)\n",
    "# ren.set_camera(position=(0, 0, 10), view_up=(0, 1, 0))\n",
    "# ren.add(odf_actor)\n",
    "# print('Saving illustration as tensor_odfs.png')\n",
    "# window.record(ren, n_frames=1, out_path='tensor_odfs_axial.png', size=(1024, 800))\n",
    "# if interactive:\n",
    "#     window.show(ren)\n",
    "\n",
    "# Sagittal View\n",
    "# index = data.shape[0] // 3\n",
    "# data_cut_y = data [index:index+1, :, :]\n",
    "# tensor_odfs = tenmodel.fit(data_cut_y).odf(sphere)\n",
    "# odf_actor = actor.odf_slicer(tensor_odfs, sphere=sphere, scale=0.5, colormap='Reds')\n",
    "# odf_actor.display(x=0)\n",
    "# ren.set_camera(position=(0, 0, 10), view_up=(0, 1, 0))\n",
    "# ren.add(odf_actor)\n",
    "# print('Saving illustration as tensor_odfs.png')\n",
    "# window.record(ren, n_frames=1, out_path='tensor_odfs_sagittal.png', size=(1024, 800))\n",
    "# if interactive:\n",
    "#     window.show(ren)\n",
    "\n",
    "# Coronal View\n",
    "# index = data.shape[1] // 2\n",
    "# data_cut_x = data [:, index:index+1, :]\n",
    "# tensor_odfs = tenmodel.fit(data_cut_x).odf(sphere)\n",
    "# odf_actor = actor.odf_slicer(tensor_odfs, sphere=sphere, scale=0.5)\n",
    "# odf_actor.display(y=0)\n",
    "# ren.set_camera(position=(0, 0, 10), view_up=(0, 1, 0))\n",
    "# ren.add(odf_actor)\n",
    "# print('Saving illustration as tensor_odfs.png')\n",
    "# window.record(ren, n_frames=1, out_path='tensor_odfs_coronal.png', size=(1024, 800))\n",
    "# if interactive:\n",
    "#     window.show(ren)\n",
    "\n",
    "#You may wonder how we knew how to set the camera. This is very easy. You just need to run window.show once \n",
    "#see how you want to see the object and then close the window and call the camera_info method which prints the position,\n",
    "#focal point and view up vectors of the camera. \n",
    "ren.camera_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
