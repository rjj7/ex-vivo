{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from nibabel.streamlines import save as save_trk\n",
    "from nibabel.streamlines import Tractogram\n",
    "from os import path\n",
    "from dipy.tracking.local import ParticleFilteringTracking\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere, Sphere, HemiSphere\n",
    "from dipy.direction import (peaks_from_model, ProbabilisticDirectionGetter)\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.io.streamline import save_trk, load_trk\n",
    "from dipy.reconst.peaks import reshape_peaks_for_visualization\n",
    "from dipy.reconst.dti import TensorModel, fractional_anisotropy, mean_diffusivity\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,auto_response, recursive_response, response_from_mask)\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.tracking.local import (LocalTracking, ThresholdTissueClassifier, ActTissueClassifier, CmcTissueClassifier)\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.utils import random_seeds_from_mask, move_streamlines\n",
    "from dipy.viz import actor, window\n",
    "from dipy.tracking.utils import target, density_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/space/hemera/1/users/cmaffei/hcp_processing/mgh_1015/')\n",
    "wd = '/space/hemera/1/users/cmaffei/hcp_processing/mgh_1015'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DWI data, bvec, bval, and binary mask\n",
    "fimg =  ('10k/data_corr.nii.gz')\n",
    "img = nib.load(fimg)\n",
    "data = img.get_data()\n",
    "print(\"Data Shape: \" + str(data.shape))\n",
    "affine = img.affine #no need to store the affine tho. \n",
    "\n",
    "#Bval and bvec file information import\n",
    "fbval= ('10k/bvals')\n",
    "fbvec = (\"10k/bvecs\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab = gradient_table(bvals,bvecs)\n",
    "# print(\"B-Values: \\n\" + str(gtab.bvecs))\n",
    "# print(gtab)\n",
    "#Read the voxel size from the image header.\n",
    "voxel_size = img.header.get_zooms()[:3]\n",
    "print ('Voxel Size: ' + str(voxel_size))\n",
    "\n",
    "#importing binary mask\n",
    "mask=(\"mask_er.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "mask = img.get_data()\n",
    "#print('mask.shape (%d, %d, %d)' % mask.shape)\n",
    "print(\"Mask Shape: \" + str(mask.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DWI data, bvec, bval, and binary mask\n",
    "fimg =  ('1k/data.nii.gz')\n",
    "img = nib.load(fimg)\n",
    "data_1k = img.get_data()\n",
    "print(\"Data Shape: \" + str(data_1k.shape))\n",
    "affine = img.affine #no need to store the affine tho. \n",
    "\n",
    "#Bval and bvec file information import\n",
    "fbval= ('1k/bvals')\n",
    "fbvec = (\"1k/bvecs\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab_1k = gradient_table(bvals,bvecs)\n",
    "print(\"B-Values: \\n\" + str(gtab.bvecs))\n",
    "print(gtab)\n",
    "#Read the voxel size from the image header.\n",
    "voxel_size = img.header.get_zooms()[:3]\n",
    "print ('Voxel Size: ' + str(voxel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_small=data[50:90,65:75,50:80]\n",
    "data_1k_small=data_1k[50:90,65:75,50:80]\n",
    "mask_small=mask[50:90,65:75,50:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE BRAIN MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask_filename = \"mask.nii.gz\"\n",
    "if path.exists(brain_mask_filename) and not recompute:\n",
    "    brain_mask_img = nib.load(brain_mask_filename).get_data()\n",
    "else:\n",
    "    recompute = True\n",
    "    _, brain_mask_img = median_otsu(data, 4, 1)\n",
    "#     save_nifti(brain_mask_filename, brain_mask_img.astype(\"uint8\"),\n",
    "#                dwi_img.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESTIMATE RESPONSE FUNCTION FOR CONSTRAINED SPHERICAL DECONVOLUTION [Tournier 2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The auto_response function will calculate FA for an ROI of radius equal to roi_radius in the center of\n",
    "#the volume and return the response function estimated in that region for the voxels with FA higher than 0.7.\n",
    "response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.6)\n",
    "\n",
    "#The response tuple contains two elements. The first is an array with the eigenvalues of the response function and the\n",
    "#second is the average S0 for this response.\n",
    "#The tensor generated from the response must be prolate (two smaller eigenvalues should be equal) and look \n",
    "#anisotropic with a ratio of second to first eigenvalue of about 0.2. Or in other words, the axial diffusivity of\n",
    "#this tensor should be around 5 times larger than the radial diffusivity.\n",
    "print(response)\n",
    "# print(ratio)\n",
    "\n",
    "# full_response = np.array([response[0][0], response[0][1],\n",
    "#                               response[0][2], response[1]])\n",
    "# np.savetxt('frf_csd_new.txt', full_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, ratio = response_from_mask(gtab, data, wm_mask)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### VISUALIZE RESPONSE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables/disables interactive visualization\n",
    "interactive = True\n",
    "\n",
    "ren = window.Renderer()\n",
    "evals = response[0]\n",
    "evecs = np.array([[0, 1, 0], [0, 0, 1], [1, 0, 0]]).T\n",
    "\n",
    "sphere = get_sphere('symmetric724')\n",
    "from dipy.sims.voxel import single_tensor_odf\n",
    "response_odf = single_tensor_odf(sphere.vertices, evals, evecs)\n",
    "# transform our data from 1D to 4D\n",
    "response_odf = response_odf[None, None, None, :]\n",
    "response_actor = actor.odf_slicer(response_odf, sphere=sphere, colormap='plasma')\n",
    "ren.add(response_actor)\n",
    "\n",
    "print('Saving illustration as csd_response.png')\n",
    "window.record(ren, out_path='csd_response.png', size=(200, 200))\n",
    "if interactive:\n",
    "    window.show(ren)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive estimatio of the response function (Tax 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing binary mask\n",
    "wm_mask=(\"1k/fa.nii.gz\")\n",
    "img = nib.load(wm_mask)\n",
    "wm_mask = img.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try recursive response\n",
    "# tenmodel = TensorModel(gtab)\n",
    "# tenfit = tenmodel.fit(data, mask)\n",
    "\n",
    "# FA = fractional_anisotropy(tenfit.evals)\n",
    "# MD = mean_diffusivity(tenfit.evals)\n",
    "wm_mask=wm_mask>0.5\n",
    "# wm_mask = (np.logical_or(FA >= 0.4, (np.logical_and(FA >= 0.3, MD >= 0.0011))))\n",
    "# nib.save(nib.Nifti1Image(FA.astype('float32'), img.affine, img.header), os.path.join(wd, 'fa.nii.gz'))\n",
    "# nib.save(nib.Nifti1Image(wm_mask.astype('float32'), img.affine, img.header), os.path.join(wd, 'wm.nii.gz'))\n",
    "\n",
    "response = recursive_response(gtab, data, mask=wm_mask, sh_order=8,\n",
    "                              peak_thr=0.03, init_fa=0.08,\n",
    "                              init_trace=0.0021, iter=20,\n",
    "                              convergence=0.01, \n",
    "                              parallel=True, nbr_processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the shape of the signal of the response function, which should be like a pancake:\n",
    "sphere = get_sphere('symmetric724')\n",
    "response_signal = response.on_sphere(sphere)\n",
    "# transform our data from 1D to 4D\n",
    "response_signal = response_signal[None, None, None, :]\n",
    "response_actor = actor.odf_slicer(\n",
    "    response_signal, sphere=sphere, colormap='plasma')\n",
    "interactive = True\n",
    "ren = window.Renderer()\n",
    "\n",
    "ren.add(response_actor)\n",
    "print('Saving illustration as csd_recursive_response.png')\n",
    "window.record(ren, out_path='csd_recursive_response_def.png', size=(200, 200))\n",
    "if interactive:\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "sphere = get_sphere('symmetric724')\n",
    "#relative_peak_threshold : float in [0., 1.] Only peaks greater than ``min + relative_peak_threshold * scale`` are\n",
    "#kept, where ``min = max(0, odf.min())`` and ``scale = odf.max() - min``. sh_order default=max sh=8\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=data_small,\n",
    "                             sphere=sphere,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25,\n",
    "                             mask=mask_small, return_odf=True, return_sh=True)\n",
    "\n",
    "#save peaks indices\n",
    "# nib.save(nib.Nifti1Image(csd_peaks.peak_indices, img.affine),\n",
    "#                  'csd_peaks_indices_new')\n",
    "# nib.save(nib.Nifti1Image(reshape_peaks_for_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_small.shape)\n",
    "print(csd_peaks.peak_values.shape)\n",
    "vals=csd_peaks.peak_values\n",
    "val=vals[15,10,10]\n",
    "print(val)\n",
    "print(val[1])\n",
    "peak_ratio=val[1]/val[0]\n",
    "print(peak_ratio)\n",
    "print(csd_peaks.odf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "sphere = get_sphere('symmetric724')\n",
    "data_small=data[30:90,65:85,40:70]\n",
    "mask_small=mask[30:90,65:85,40:70]\n",
    "#relative_peak_threshold : float in [0., 1.] Only peaks greater than ``min + relative_peak_threshold * scale`` are\n",
    "#kept, where ``min = max(0, odf.min())`` and ``scale = odf.max() - min``. sh_order default=max sh=8\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=data_small,\n",
    "                             sphere=sphere,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25,\n",
    "                             mask=mask_small, return_odf=True, return_sh=True)\n",
    "\n",
    "#save peaks indices\n",
    "# nib.save(nib.Nifti1Image(csd_peaks.peak_indices, img.affine),\n",
    "#                  'csd_peaks_indices_new')\n",
    "# nib.save(nib.Nifti1Image(reshape_peaks_for_visualization(csd_peaks), img.affine),\n",
    "#              'csd_peaks_new.nii.gz')\n",
    "\n",
    "\n",
    "#Compute CSD fODF in mrtrix basis for visuakization in mrview\n",
    "# csd_peaks_mrtrix = peaks_from_model(model=csd_model,\n",
    "#                              data=data,\n",
    "#                              sphere=sphere,\n",
    "#                              relative_peak_threshold=.5,\n",
    "#                              min_separation_angle=25, sh_basis_type='mrtrix',\n",
    "#                              mask=mask, return_odf=True, return_sh=True)\n",
    "\n",
    "#save odf\n",
    "# nib.save(nib.Nifti1Image(csd_peaks.shm_coeff.astype(np.float32),\n",
    "#                                   img.affine, img.header), 'odf_recursive_csd.nii.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading odfs\n",
    "sphere = get_sphere('symmetric724')\n",
    "from dipy.reconst.shm import sh_to_sf\n",
    "fimg = (\"10k/odfs_01_01_body_cc.nii.gz\")\n",
    "img = nib.load(fimg)\n",
    "odfs = img.get_data()\n",
    "odfs_tosf = sh_to_sf(odfs, sphere, sh_order=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZE FODs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enables/disables interactive visualization\n",
    "\n",
    "fa= ('dtifit_FA.nii.gz')\n",
    "img = nib.load(fa)\n",
    "fa=img.get_data()\n",
    "slf_mask=(\"rot_files/slf1_oblique_res.nii.gz\")\n",
    "img = nib.load(slf_mask)\n",
    "slf_mask = img.get_data()\n",
    "cc_mask=(\"rot_files/cc_oblique_res.nii.gz\")\n",
    "img = nib.load(cc_mask)\n",
    "cc_mask = img.get_data()\n",
    "\n",
    "ren = window.Renderer()\n",
    "interactive = True\n",
    "fodf_spheres = actor.odf_slicer(odfs_tosf, sphere=sphere, scale=0.5, norm=False, colormap='jet')\n",
    "fodf_spheres.display_extent(61, 61, 0, 140, 0, 96)\n",
    "\n",
    "slice_actor = actor.slicer(fa)\n",
    "slice_actor.display(slice_actor.shape[0]//2, None, None)\n",
    "cc_actor = actor.contour_from_roi(slf_mask,\n",
    "                                        color=[0.7,0,0], opacity=0.2)\n",
    "slf_actor = actor.contour_from_roi(cc_mask,\n",
    "                                        color=[0.1,0.6,0.2], opacity=0.2)\n",
    "\n",
    "ren.set_camera(position=(10, 0, 0))\n",
    "ren.add(fodf_spheres)\n",
    "ren.add(slice_actor)\n",
    "ren.add(slf_actor)\n",
    "ren.add(cc_actor)\n",
    "\n",
    "# print('Saving illustration as csd_odfs.png')\n",
    "# window.record(ren, out_path='csd_fods.png', size=(600, 600))\n",
    "if interactive:\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZE PEAKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window.clear(ren)\n",
    "# fodf_peaks = actor.peak_slicer(csd_peaks.peak_dirs, csd_peaks.peak_values, colors=None)\n",
    "# ren.add(fodf_peaks)\n",
    "# print('Saving illustration as csd_peaks.png')\n",
    "# window.record(ren, out_path='csd_peaks.png', size=(600, 600))\n",
    "# if interactive:\n",
    "#     window.show(ren)\n",
    "\n",
    "interactive = True\n",
    "ren = window.Renderer()\n",
    "# ren.add(fodf_spheres)\n",
    "ren.add(actor.peak_slicer(\n",
    "    csd_peaks.peak_dirs, csd_peaks.peak_values, colors=None))\n",
    "\n",
    "if interactive:\n",
    "    window.show(ren, size=(900, 900))\n",
    "else:\n",
    "    window.record(\n",
    "        ren, out_path='csd_direction_field.png', size=(900, 900))\n",
    "    \n",
    "#to add the odf to the peaks    \n",
    "fodf_spheres.GetProperty().SetOpacity(0.4)\n",
    "\n",
    "ren.add(fodf_spheres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRACTOGRAPHY tissue classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = nib.load('dtifit_FA.nii.gz').get_data()\n",
    "\n",
    "tissue_classifier = ThresholdTissueClassifier(fa, 0.1)\n",
    "# seeds = random_seeds_from_mask(fa > 0.5, seeds_count=2)\n",
    "streamline_generator = LocalTracking(\n",
    "   prob_dg, tissue_classifier, seeds, affine=np.eye(4),\n",
    "    step_size=0.75)\n",
    "\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "save_trk(\"prova_tissue_class.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "print(\"Number of streamlines: \" + str(len(streamlines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZE STREAMLINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ren.clear()\n",
    "ren.add(actor.line(streamlines))\n",
    "\n",
    "if interactive:\n",
    "    window.show(ren, size=(900, 900))\n",
    "else:\n",
    "    print('Saving illustration as det_streamlines.png')\n",
    "    window.record(ren, out_path='det_streamlines.png', size=(900, 900))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBABILISTIC TRACTOGRAPHY\n",
    "\n",
    "CSD represents each voxel in the data set as a collection of small white matter fibers with different orientations.\n",
    "The density of fibers along each orientation is known as the Fiber Orientation Distribution (FOD). \n",
    "In order to perform probabilistic fiber tracking, we pick a fiber from the FOD at random at each new location along\n",
    "the streamline. Note: one could use this model to perform deterministic fiber tracking by always tracking along the\n",
    "directions that have the most fibers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the CSD model represents the FOD using the spherical harmonic basis, we can use the from_shcoeff \n",
    "#method to create the direction getter. This direction getter will randomly sample directions from the FOD each \n",
    "#time the tracking algorithm needs to take another step.\n",
    "\n",
    "prob_dg = ProbabilisticDirectionGetter.from_shcoeff(odfs, max_angle=45, sphere=sphere)\n",
    "\n",
    "#Another way is to represent the FOD using a discrete sphere\n",
    "#This discrete FOD can be used by the ProbabilisticDirectionGetter\n",
    "#as a PMF for sampling tracing directions. e need to clip the FOD \n",
    "#to use it as a PMF because the latter cannot have negative values\n",
    "#However this way takes more memory, because it samples the PMF and \n",
    "#it holds it in memory (that s why we use small sphere instead of default sphere)\n",
    "\n",
    "# from dipy.data import small_sphere\n",
    "# odf = gqfit.odf(small_sphere)\n",
    "# pmf = odf.clip(min=0)\n",
    "# prob_dg = ProbabilisticDirectionGetter.from_pmf(pmf, max_angle=30, sphere=small_sphere)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading seed mask\n",
    "seed_mask=(\"t12fa_n_pve_2_fs_nearest.nii.gz\")\n",
    "imgm = nib.load(seed_mask)\n",
    "seed_mask = imgm.get_data()\n",
    "seed_mask = seed_mask > 0.5\n",
    "print('seed_mask.shape (%d, %d, %d)' % seed_mask.shape)\n",
    "\n",
    "#defining seeds\n",
    "#local tracker assumes that the data is sampled on a regular grid. seeds(same space as the affine!). \n",
    "seeds = random_seeds_from_mask(seed_mask, seeds_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANATOMICALLY CONSTRAINED TRACTOGRAPHY (ACT)\n",
    "\n",
    "\n",
    "Anatomically-constrained tractography (ACT) [Smith2012] uses information from anatomical images to determine when the \n",
    "tractography stops. The include_map defines when the streamline reached a ‘valid’ stopping region (e.g. gray matter\n",
    "partial volume estimation (PVE) map) and the exclude_map defines when the streamline reached an ‘invalid’ stopping\n",
    "region (e.g. corticospinal fluid PVE map). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load PVE maps\n",
    "img_pve_gm = nib.load('t12fa_n_pve_1_res.nii.gz')\n",
    "img_pve_csf = nib.load('t12fa_n_pve_0_res.nii.gz')\n",
    "img_pve_wm = nib.load('t12fa_n_pve_2_res.nii.gz')\n",
    "              \n",
    "# background = np.ones(img_pve_gm.shape)\n",
    "# background[(img_pve_gm.get_data() +\n",
    "#             img_pve_wm.get_data() +\n",
    "#             img_pve_csf.get_data()) > 0] = 0\n",
    "                       \n",
    "# include_map = img_pve_gm.get_data()\n",
    "# include_map[background > 0] = 1\n",
    "# exclude_map = img_pve_csf.get_data()\n",
    "\n",
    "# act_classifier = ActTissueClassifier(include_map, exclude_map)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.subplot(121)\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# plt.imshow(include_map[:, :, data.shape[2] // 2].T, cmap='gray', origin='lower',\n",
    "#            interpolation='nearest')\n",
    "# plt.subplot(122)\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# plt.imshow(exclude_map[:, :, data.shape[2] // 2].T, cmap='gray', origin='lower',\n",
    "#            interpolation='nearest')\n",
    "# fig.tight_layout()\n",
    "# fig.savefig('act_maps.png')\n",
    "\n",
    "\n",
    "# # Maxlen: Maximum number of steps to track from seed. Used to prevent infinite loops. \n",
    "# # return_all : bool If true, return all generated streamlines, otherwise only streamlines reaching end points \n",
    "# # or exiting the image.\n",
    "# all_streamlines_act_classifier = LocalTracking(prob_dg,\n",
    "#                                                act_classifier,\n",
    "#                                                seeds, \n",
    "#                                                affine=np.eye(4), step_size=0.75,\n",
    "#                                                return_all=True)\n",
    "\n",
    "# streamlines = Streamlines(all_streamlines_act_classifier)\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/sscilpy_mrtrix_comparison/10000/from_mgh/csd_prob_10npv_act_45angle.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMC (Continuous Map Criterior)\n",
    "As ACT but instead of considering PEVs as discrete values, it uses to assign weights (Girard et al 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local import ParticleFilteringTracking\n",
    "from dipy.tracking.local import CmcTissueClassifier\n",
    "voxel_size = np.average(img_pve_wm.get_header()['pixdim'][1:4])\n",
    "step_size = 0.75\n",
    "\n",
    "cmc_classifier = CmcTissueClassifier.from_pve(img_pve_wm.get_data(),\n",
    "                                              img_pve_gm.get_data(),\n",
    "                                              img_pve_csf.get_data(),\n",
    "                                              step_size=step_size,\n",
    "                                              average_voxel_size=voxel_size)\n",
    "\n",
    "all_streamlines_act_classifier = LocalTracking(prob_dg,\n",
    "                                               cmc_classifier,\n",
    "                                               seeds, \n",
    "                                               affine=np.eye(4), step_size=0.75,\n",
    "                                               return_all=True)\n",
    "\n",
    "streamlines = Streamlines(all_streamlines_act_classifier)\n",
    "save_trk(\"prova_nuova_pve_45_075.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CST extraction\n",
    "#load ROIs\n",
    "img = nib.load ('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/rois/ic_l_con.nii.gz')\n",
    "ic = img.get_data()\n",
    "img =  nib.load ('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/rois/mb_l_con.nii.gz')\n",
    "mb = img.get_data()\n",
    "\n",
    "#load csd tractogram\n",
    "streamlines_load, hdr = load_trk('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/csd_prob_npv1_comparisontogqi.trk')\n",
    "streamlines_load = Streamlines(streamlines_load)\n",
    "streamlines_load = move_streamlines(streamlines_load, np.eye(4), img.affine)\n",
    "\n",
    "cst_streamlines_int = target(streamlines_load, ic, affine=np.eye(4))\n",
    "cst_streamlines = target(cst_streamlines_int, mb, affine=np.eye(4))\n",
    "cst_csd = Streamlines(cst_streamlines)\n",
    "\n",
    "#save cst csd\n",
    "# save_trk('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/cst_csd_1npv_recursive_prob.trk',\n",
    "#          cst_csd,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "#load gqi tractogram\n",
    "streamlines_load, hdr = load_trk('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/prob_gqi_odf_norm_pmfthr04.trk')\n",
    "streamlines_load = Streamlines(streamlines_load)\n",
    "streamlines_load = move_streamlines(streamlines_load, np.eye(4), img.affine)\n",
    "\n",
    "cst_streamlines_int = target(streamlines_load, ic, affine=np.eye(4))\n",
    "cst_streamlines = target(cst_streamlines_int, mb, affine=np.eye(4))\n",
    "cst_gqi = Streamlines(cst_streamlines)\n",
    "\n",
    "#save \n",
    "# save_trk('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/cst_gqi_1npv_pmf04_prob.trk',\n",
    "#           cst_gqi,\n",
    "#           img.affine,\n",
    "#           shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.viz import window, actor\n",
    "from dipy.viz.colormap import line_colors\n",
    "\n",
    "# Enables/disables interactive visualization\n",
    "interactive = True\n",
    "\n",
    "# Make display objects\n",
    "cst_csd_streamlines_actor = actor.line(cst_csd, (1., 0.5, 0))\n",
    "cst_gqi_streamlines_actor = actor.line(cst_gqi, (1., 1., 0), opacity=0.6)\n",
    "# cc_ROI_actor = actor.contour_from_roi(cc_slice, color=(1., 1., 0.),\n",
    "#                                      opacity=0.5)\n",
    "\n",
    "vol_actor = actor.slicer(FA)   \n",
    "vol_actor.display(x=90)\n",
    "vol_actor.opacity(0.6)\n",
    "# Add display objects to canvas\n",
    "r = window.Renderer()\n",
    "r.add(cst_csd_streamlines_actor)\n",
    "r.add(cst_gqi_streamlines_actor)\n",
    "r.add(vol_actor)\n",
    "\n",
    "# Save figures\n",
    "r.set_camera(position=[-1, 0, 0], view_up=[0, 0, 1])\n",
    "window.record(r, n_frames=1, out_path='/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/cst_comparison.png',\n",
    "              size=(800, 800))\n",
    "if interactive:\n",
    "    window.show(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
