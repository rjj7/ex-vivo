{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_sphere, HemiSphere\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.io.streamline import save_trk\n",
    "from dipy.direction import (peaks_from_model, ProbabilisticDirectionGetter)\n",
    "from dipy.reconst.gqi import GeneralizedQSamplingModel\n",
    "from dipy.reconst.peaks import reshape_peaks_for_visualization\n",
    "from dipy.tracking import utils\n",
    "from dipy.tracking.local import (ThresholdTissueClassifier, LocalTracking,ActTissueClassifier)\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.utils import random_seeds_from_mask\n",
    "from dipy.viz import window, actor, fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,auto_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-027a3c54a575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/10k.nii.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#bval bvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/site-packages/nibabel/dataobj_images.pyc\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, caching)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/site-packages/nibabel/arrayproxy.pyc\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# Read array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/site-packages/nibabel/arrayproxy.pyc\u001b[0m in \u001b[0;36mget_unscaled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/site-packages/nibabel/volumeutils.pyc\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'readinto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mn_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                     \u001b[0mreadsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_read_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0muncompress\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munused_data\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m_add_read_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffffL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrastart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrabuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrabuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrastart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dwi\n",
    "fimg = (\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/10k.nii.gz\")\n",
    "img = nib.load(fimg)\n",
    "data = img.get_data()\n",
    "affine = img.affine\n",
    "#bval bvec \n",
    "fbval=(\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/bvals\")\n",
    "fbvec = (\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/bvecs\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab = gradient_table(bvals,bvecs)\n",
    "print(\"Data 1k Shape: \" + str(data.shape))\n",
    "\n",
    "#importing brain mask\n",
    "mask=(\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/1000/mask.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "brain_mask = img.get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Sphere for discrete sampling directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = get_sphere('symmetric642')\n",
    "sphere.vertices = sphere.vertices.astype('float')\n",
    "sphere.edges = sphere.edges.astype('uint16')\n",
    "sphere.faces = sphere.faces.astype('uint16')\n",
    "sphere.phi = sphere.phi.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting GQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model and apply it to the data.\n",
    "gqmodel = GeneralizedQSamplingModel(gtab, sampling_length=0.5)\n",
    "\n",
    "gqi = peaks_from_model(model=gqmodel,\n",
    "                           data=data,\n",
    "                           sphere=sphere,\n",
    "                           relative_peak_threshold=.5,        \n",
    "                           min_separation_angle=25,\n",
    "                           mask=brain_mask, return_odf=True,\n",
    "                           normalize_peaks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Visualize Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enables/disables interactive visualization\n",
    "interactive = True\n",
    "ren = window.Renderer()\n",
    "window.clear(ren)\n",
    "gq_peaks = actor.peak_slicer(gqi.peak_dirs, gqi.peak_values, colors=None)\n",
    "ren.set_camera(position=(0, 10, 0))\n",
    "ren.add(gq_peaks)\n",
    "\n",
    "if interactive:\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute GFA\n",
    "GFA = gqi.gfa\n",
    "save_nifti('/space/hemera/1/users/cmaffei/habenoula_mgh_1010/gfa_map.nii.gz', GFA, affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fitting CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, ratio = auto_response(\n",
    "        gtab, data, roi_radius=10, fa_thr=0.7)\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "\n",
    "sphere = get_sphere('symmetric724')\n",
    "\n",
    "csd = peaks_from_model(\n",
    "        model=csd_model, data=data, sphere=sphere, mask=brain_mask,\n",
    "        relative_peak_threshold=.5, min_separation_angle=25,\n",
    "        parallel=True, return_sh=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Tractography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seeds and Tissue classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTA Shape: (140, 140, 96)\n",
      "HB Shape: (140, 140, 96)\n"
     ]
    }
   ],
   "source": [
    "#Load habenoula and VTA masks\n",
    "mask=(\"/cluster/scratch/friday/ay/mgh_1010/avg_VTA_L_R_thr_60_bin_mul_alpha_04_all_grp_mask.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "VTA = img.get_data()\n",
    "print(\"VTA Shape: \" + str(VTA.shape))\n",
    "\n",
    "mask=(\"/cluster/scratch/friday/ay/mgh_1010/Hb_mask_peak_voxel.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "HB = img.get_data()\n",
    "print(\"HB Shape: \" + str(HB.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#local tracker assumes that the data is sampled on a regular grid. seeds(same space as the affine!). \n",
    "seed_HB = random_seeds_from_mask(HB, seeds_count=1000)\n",
    "seed_VTA = random_seeds_from_mask(VTA, seeds_count=1000)\n",
    "\n",
    "#Define a tissue classifier. Streamlines will stop propagating for GFA < .25\n",
    "# tissue_classifier = ThresholdTissueClassifier(GFA, .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set ACT classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import PVE maps\n",
    "img_pve_gm = nib.load('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/T12diff_pve_1_res_con.nii.gz')\n",
    "img_pve_csf = nib.load('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/T12diff_pve_0_res_con.nii.gz')\n",
    "img_pve_wm = nib.load('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/T12diff_pve_2_res_con.nii.gz')\n",
    "\n",
    "# The background of the anatomical image should be added to the include_map\n",
    "# to keep streamlines exiting the brain (e.g. through the brain stem). The ACT tissue classifier uses a trilinear \n",
    "# interpolation at the tracking position.\n",
    "background = np.ones(img_pve_gm.shape)\n",
    "background[(img_pve_gm.get_data() +\n",
    "            img_pve_wm.get_data() +\n",
    "            img_pve_csf.get_data()) > 0] = 0\n",
    "                       \n",
    "include_map = img_pve_gm.get_data()\n",
    "include_map[background > 0] = 1\n",
    "exclude_map = img_pve_csf.get_data()\n",
    "\n",
    "act_classifier = ActTissueClassifier(include_map, exclude_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministic Tractography CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamline_generator = LocalTracking(\n",
    "#         csd, tissue_classifier, seed_VTA, affine=np.eye(4),\n",
    "#         step_size=0.75)\n",
    "# streamlines = Streamlines(streamline_generator)\n",
    "# #Save the trk file\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_det_csd_tc.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "# streamline_generator = LocalTracking(\n",
    "#         csd, tissue_classifier, seed_HB, affine=np.eye(4),\n",
    "#         step_size=0.75)\n",
    "# streamlines = Streamlines(streamline_generator)\n",
    "# #Save the trk file\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_det_csd_tc.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        csd, act_classifier, seed_VTA, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_det_csd_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        csd, act_classifier, seed_HB, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_det_csd_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Tractography CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dg = ProbabilisticDirectionGetter.from_shcoeff(csd.shm_coeff, max_angle=30, sphere=sphere)\n",
    "\n",
    "# streamline_generator = LocalTracking(\n",
    "#         prob_dg, tissue_classifier, seed_VTA, affine=np.eye(4),\n",
    "#         step_size=0.75)\n",
    "# streamlines = Streamlines(streamline_generator)\n",
    "# #Save the trk file\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_prob_csd_tc.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "# streamline_generator = LocalTracking(\n",
    "#         prob_dg, tissue_classifier, seed_HB, affine=np.eye(4),\n",
    "#         step_size=0.75)\n",
    "# streamlines = Streamlines(streamline_generator)\n",
    "# #Save the trk file\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_prob_csd_tc.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        prob_dg, act_classifier, seed_VTA, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_prob_csd_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        prob_dg, act_classifier, seed_HB, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_prob_csd_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministic Tractography GQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamline_generator = LocalTracking(\n",
    "#         gqi, tissue_classifier, seed_VTA, affine=np.eye(4),\n",
    "#         step_size=0.75)\n",
    "# streamlines = Streamlines(streamline_generator)\n",
    "# #Save the trk file\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_det_gqi_tc.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "# streamline_generator = LocalTracking(\n",
    "#         gqi, tissue_classifier, seed_HB, affine=np.eye(4),\n",
    "#         step_size=0.75)\n",
    "# streamlines = Streamlines(streamline_generator)\n",
    "# #Save the trk file\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_det_gqi_tc.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        gqi, act_classifier, seed_VTA, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_det_gqi_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        gqi, act_classifier, seed_HB, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_det_gqi_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Tractography GQI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = gqi.odf.clip(min=0)\n",
    "prob_dg = ProbabilisticDirectionGetter.from_pmf(pmf, max_angle=30, sphere=sphere)\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        prob_dg, tissue_classifier, seed_VTA, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_prob_gqi_tc.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        prob_dg, tissue_classifier, seed_HB, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_prob_gqi_tc.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        prob_dg, act_classifier, seed_VTA, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/vta_1000seeds_prob_gqi_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "streamline_generator = LocalTracking(\n",
    "        prob_dg, act_classifier, seed_HB, affine=np.eye(4),\n",
    "        step_size=0.75)\n",
    "streamlines = Streamlines(streamline_generator)\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/10k/hb_1000seeds_prob_gqi_act.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BootStrap GQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.direction import BootDirectionGetter\n",
    "from dipy.data import small_sphere\n",
    "\n",
    "boot_dg_gq = BootDirectionGetter.from_data(data, gqmodel, max_angle=30.,\n",
    "                                           sphere=sphere)\n",
    "\n",
    "boot_streamline_generator = LocalTracking(boot_dg_gq, tissue_classifier, seed_HB,\n",
    "                                          affine=np.eye(4), step_size=.75)\n",
    "\n",
    "streamlines = Streamlines(boot_streamline_generator)\n",
    "\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/1k/hb_1000seeds_gqi_bootstrap_tc.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n",
    "\n",
    "boot_streamline_generator = LocalTracking(boot_dg_gq, tissue_classifier, seed_VTA,\n",
    "                                          affine=np.eye(4), step_size=.75)\n",
    "\n",
    "streamlines = Streamlines(boot_streamline_generator)\n",
    "\n",
    "#Save the trk file\n",
    "save_trk(\"/space/hemera/1/users/cmaffei/habenoula_mgh_1010/1k/vta_1000seeds_gqi_bootstrap_tc.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
