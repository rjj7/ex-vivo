{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import os\n",
    "\n",
    "from dipy.core.gradients import gradient_table, GradientTable\n",
    "from dipy.core.ndindex import ndindex\n",
    "from dipy.core.sphere import faces_from_sphere_vertices, unique_edges\n",
    "from dipy.data import get_sphere, HemiSphere, Sphere\n",
    "from dipy.direction.peaks import peak_directions\n",
    "from dipy.direction import (peaks_from_model, ProbabilisticDirectionGetter)\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.io.streamline import load_trk\n",
    "from dipy.io.streamline import save_trk\n",
    "from dipy.reconst.gqi import GeneralizedQSamplingModel\n",
    "from dipy.reconst.peaks import reshape_peaks_for_visualization\n",
    "from dipy.reconst.shm import sf_to_sh, sph_harm_lookup, smooth_pinv, sh_to_sf\n",
    "from dipy.tracking import utils\n",
    "from dipy.tracking.local import (ThresholdTissueClassifier, LocalTracking,ActTissueClassifier)\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking.utils import random_seeds_from_mask\n",
    "from dipy.viz import window, actor, fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,auto_response, recursive_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/space/neptune/1/users/srf29/diffusion/kanwishercon/db/vols_dti/mgh/kancon02/dti/')\n",
    "wd = '/autofs/space/neptune/1/users/srf29/diffusion/kanwishercon/db/vols_dti/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272,)\n",
      "Mask Shape: (140, 140, 78)\n"
     ]
    }
   ],
   "source": [
    "fimg = (\"data.nii.gz\")\n",
    "img = nib.load(fimg)\n",
    "data = img.get_data()\n",
    "\n",
    "fbval=(\"bvals\")\n",
    "fbvec = (\"/space/hemera/1/users/cmaffei/data_nancy/bvecs-x\")\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "gtab = gradient_table(bvals,bvecs)\n",
    "print(gtab.bvals.shape)\n",
    "\n",
    "#importing binary mask\n",
    "mask=(\"nodif_brain_mask.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "mask = img.get_data()\n",
    "print(\"Mask Shape: \" + str(mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere642 = get_sphere('symmetric642')\n",
    "sphere642.vertices = sphere642.vertices.astype('float')\n",
    "sphere642.edges = sphere642.edges.astype('uint16')\n",
    "sphere642.faces = sphere642.faces.astype('uint16')\n",
    "sphere642.phi = sphere642.phi.astype('float')\n",
    "sphere764 = get_sphere('symmetric724')\n",
    "# sphere = HemiSphere.from_sphere(sphere=sphere642, tol=1e-01)\n",
    "# sphere.vertices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_values = np.sqrt(gtab.bvals * 0.01506)\n",
    "tmp=np.tile(l_values, (3,1))\n",
    "gradsT = gtab.bvecs.T\n",
    "b_vector = gradsT * tmp\n",
    "b_vector = b_vector.T\n",
    "gqi_vector = np.real(np.sinc(np.dot(b_vector, sphere642.vertices.T)* 1.6/np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing odf for one voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox = data[52, 44, 60, :]\n",
    "odf = np.dot(vox, gqi_vector)\n",
    "odf = odf - (np.abs(odf).min())\n",
    "odf = odf / (np.abs(odf).max())\n",
    "# plotting values\n",
    "plt.plot(odf)\n",
    "plt.title('voxel_plot')\n",
    "plt.show()\n",
    "\n",
    "direction, pk, indices = peak_directions(odf, sphere642, relative_peak_threshold=.5, min_separation_angle=25)\n",
    "pk\n",
    "print(pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing ODF for all volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 140, 78, 642)\n"
     ]
    }
   ],
   "source": [
    "odfs = np.dot(data, gqi_vector)\n",
    "print(odfs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking that I obtain exactly the same thing when computing odf in dipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute brain mask for following steps\n",
    "from dipy.segment.mask import median_otsu\n",
    "maskdata, mask = median_otsu(data, 3, 1, False,\n",
    "                             vol_idx=range(10, 50), dilate=2)\n",
    "save_nifti('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/1000/from_mgh/dsi_studio/linebyline/mask.nii.gz', mask.astype(\"uint8\"),\n",
    "               img.affine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gqmodel = GeneralizedQSamplingModel(gtab, 'standard', sampling_length=1)\n",
    "\n",
    "gqpeaks = peaks_from_model(model=gqmodel, data=data,\n",
    "                           sphere=sphere642, mask=mask,\n",
    "                           relative_peak_threshold=.5,\n",
    "                           min_separation_angle=25,\n",
    "                           return_odf=True,\n",
    "                           normalize_peaks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODF Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autofs/space/tinia_001/users/chiara/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "#min/max normalization\n",
    "ijk = np.ascontiguousarray(np.array(np.nonzero(mask)).T)\n",
    "shape = data.shape[:-1]\n",
    "odfs_norm = np.zeros ((shape + (len(sphere642.vertices),)))\n",
    "\n",
    "for (k, center) in enumerate(ijk):\n",
    "    m = odfs[tuple(center.astype(np.int))].copy()\n",
    "    m = m - (np.abs(m).min())\n",
    "    m = m / (np.abs(m).max())\n",
    "    odfs_norm[tuple(center.astype(np.int))] = m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nib.save(nib.Nifti1Image(odfs_norm.astype(np.float32),\n",
    "                                  img.affine, img.header), 'odfs/gqi_odfs_l14_dir642.nii.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peaks Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract peaks values and directions\n",
    "#set maximum number of peaks relatove peak threshold and min separation angle\n",
    "npeaks = 3\n",
    "relative_peak_threshold=.5\n",
    "min_separation_angle=25\n",
    "shape=mask.shape    \n",
    "peak_dirs = np.zeros ((shape + (npeaks, 3)))\n",
    "peak_values = np.zeros ((shape + (npeaks,)))\n",
    "peak_indices = np.zeros((shape + (npeaks,)), dtype='int')\n",
    "\n",
    "odfs_norm =odfs_norm.astype(float)\n",
    "\n",
    "for idx in ndindex(shape):\n",
    "    if not mask[idx]:\n",
    "        continue\n",
    "    direction, pk, indices = peak_directions(odfs_norm[idx], sphere642, relative_peak_threshold, min_separation_angle)\n",
    "    n = min(npeaks, pk.shape[0])\n",
    "    \n",
    "    peak_dirs[idx][:n] = direction[:n]\n",
    "    peak_values[idx][:n] = pk[:n]\n",
    "    peak_indices[idx][:n] = indices[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,recursive_response)\n",
    "from dipy.reconst.dti import TensorModel, fractional_anisotropy, mean_diffusivity\n",
    "\n",
    "#try recursive response\n",
    "tenmodel = TensorModel(gtab)\n",
    "tenfit = tenmodel.fit(data, mask)\n",
    "\n",
    "FA = fractional_anisotropy(tenfit.evals)\n",
    "MD = mean_diffusivity(tenfit.evals)\n",
    "wm_mask = (np.logical_or(FA >= 0.4, (np.logical_and(FA >= 0.15, MD >= 0.0011))))\n",
    "\n",
    "response = recursive_response(gtab, data, mask=wm_mask, sh_order=8,\n",
    "                              peak_thr=0.01, init_fa=0.08,\n",
    "                              init_trace=0.0021, iter=8, convergence=0.001,\n",
    "                              parallel=True)\n",
    "\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=data,\n",
    "                             sphere=sphere642,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25, mask=mask,\n",
    "                             normalize_peaks=True,\n",
    "                             return_odf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Normalized ODFs and peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interactive = True\n",
    "r = window.Renderer()\n",
    "\n",
    "gqi_odfs_actor = actor.odf_slicer(odfs_norm, sphere=sphere642, scale=0.6, norm=True, colormap= 'jet')\n",
    "# gqi_odfs_actor_new = actor.odf_slicer(odfs_gqi_new, sphere=sphere642, scale=0.6, norm=True, colormap= 'jet')\n",
    "gqi_peaks_actor = actor.peak_slicer(peak_dirs, peak_values, colors=(1,0,0))\n",
    "# csd_odfs_actor = actor.odf_slicer(odfs_csd, sphere=sphere642, scale=0.6, norm=False, colormap='jet')\n",
    "# csd_peaks_actor = actor.peak_slicer(csd_peaks.peak_dirs, csd_peaks.peak_values, colors=(1,0,0))\n",
    "\n",
    "gqi_odfs_actor.GetProperty().SetOpacity(0.4)\n",
    "\n",
    "gqi_odfs_actor.display_extent(10, 10, 0, 30, 0, 50)\n",
    "# gqi_odfs_actor_new.display_extent(0, 20, 10, 10, 0, 20)\n",
    "gqi_peaks_actor.display_extent(25, 25, 0, 30, 0, 50)\n",
    "# csd_odfs_actor.display_extent(60, 60, 0, 140, 0, 96)\n",
    "# csd_peaks_actor.display_extent(83, 83, 69, 69, 59, 59)\n",
    "# seedroi_actor = actor.contour_from_roi(slf_mask,\n",
    "#                                        color=[0,1,1], opacity=0.5)\n",
    "\n",
    "r.set_camera(position=(10, 0, 0))\n",
    "# gqi_odfs_actor.display(z=0)\n",
    "r.add(gqi_odfs_actor)\n",
    "# r.add(gqi_odfs_actor_new)\n",
    "r.add(gqi_peaks_actor)\n",
    "# r.add(csd_odfs_actor)\n",
    "# r.add(csd_peaks_actor)\n",
    "# r.add(seedroi_actor)\n",
    "\n",
    "# print('Saving illustration as gqi_odfs.png')\n",
    "# window.record(r, out_path='odfs.png', size=(600, 600))\n",
    "if interactive:\n",
    "    window.show(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Mrtrix Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In both methods the  resulting ODF are flipped in Mrtrix even if starting from the \n",
    "# same data they are not. \n",
    "\n",
    "odf_mrtrix = sf_to_sh(odfs_norm, sphere642, sh_order=6, basis_type='mrtrix')\n",
    "\n",
    "#save odf\n",
    "nib.save(nib.Nifti1Image(odf_mrtrix.astype(np.float32),\n",
    "                                  img.affine, img.header), '/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/prova_flip/gqi_odf_mrtrix.nii.gz')\n",
    "\n",
    "odf_mrtrix = sf_to_sh(csd_peaks.odf, sphere642, sh_order=6, basis_type='mrtrix')\n",
    "\n",
    "#save odf\n",
    "nib.save(nib.Nifti1Image(odf_mrtrix.astype(np.float32),\n",
    "                                  img.affine, img.header), '/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/prova_flip/csd_odf_mrtrix.nii.gz')\n",
    "\n",
    "\n",
    "#some trickery to put the coefficients in the same order as MRtrix\n",
    "# sh_coeff =  csd_peaks.shm_coeff\n",
    "# sh_coeff_mrtrix = np.zeros(sh_coeff.shape)\n",
    "# sh_coeff_mrtrix[...,0] = sh_coeff[...,0]\n",
    "# sh_coeff_mrtrix[...,1:6] = sh_coeff[...,5:0:-1]\n",
    "# sh_coeff_mrtrix[...,6:15] = sh_coeff[...,14:5:-1]\n",
    "\n",
    "# nib.save(nib.Nifti1Image(sh_coeff_mrtrix.astype(np.float32), img.affine, img.header), '/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/csd_recursive_fod_mrtrix_prova.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading odfs\n",
    "fimg = (\"../../scilpy_mrtrix_comparison/multishell/from_mgh/odfs/gqi_odfs_l14_dir642.nii.gz\")\n",
    "img = nib.load(fimg)\n",
    "odfs_gqi = img.get_data()\n",
    "\n",
    "fimg = ('all_shells/odfs_norm.nii.gz')\n",
    "img = nib.load(fimg)\n",
    "odfs_gqi_new = img.get_data()\n",
    "\n",
    "# fimg = (\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/odf_recursive_csd.nii.gz\")\n",
    "# img = nib.load(fimg)\n",
    "# odfs_csd = img.get_data()\n",
    "# odfs_csd = sh_to_sf(odfs_csd, sphere642, sh_order=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Tractography Test on Normalized ODF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = odfs_gqi.clip(min=0)\n",
    "prob_dg = ProbabilisticDirectionGetter.from_pmf(pmf, max_angle=30, sphere=sphere642, pmf_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the seeds from a white matter binary mask\n",
    "seed_mask=(\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/wm_mask_bin_res_con.nii.gz\")\n",
    "imgm = nib.load(seed_mask)\n",
    "seed_mask = imgm.get_data()\n",
    "seeds = random_seeds_from_mask(seed_mask, seeds_count=10)\n",
    "\n",
    "#Import PVE maps\n",
    "img_pve_gm = nib.load('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/T12diff_pve_1_res_con.nii.gz')\n",
    "img_pve_csf = nib.load('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/T12diff_pve_0_res_con.nii.gz')\n",
    "img_pve_wm = nib.load('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/structural/T12diff_pve_2_res_con.nii.gz')\n",
    "\n",
    "# The background of the anatomical image should be added to the include_map\n",
    "# to keep streamlines exiting the brain (e.g. through the brain stem). The ACT tissue classifier uses a trilinear \n",
    "# interpolation at the tracking position.\n",
    "# background = np.ones(img_pve_gm.shape)\n",
    "# background[(img_pve_gm.get_data() +\n",
    "#             img_pve_wm.get_data() +\n",
    "#             img_pve_csf.get_data()) > 0] = 0\n",
    "                       \n",
    "# include_map = img_pve_gm.get_data()\n",
    "# include_map[background > 0] = 1\n",
    "# exclude_map = img_pve_csf.get_data()\n",
    "\n",
    "# act_classifier = ActTissueClassifier(include_map, exclude_map)\n",
    "# streamline_generator = LocalTracking(\n",
    "#         prob_dg, act_classifier, seeds, affine=np.eye(4),\n",
    "#         step_size=0.75)\n",
    "# streamlines = Streamlines(streamline_generator)\n",
    "# #Save the trk file\n",
    "# save_trk(\"/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/prob_gqi_odf_norm_pmfthr04_npv10_angle45.trk\",\n",
    "#          streamlines,\n",
    "#          img.affine,\n",
    "#          shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local import CmcTissueClassifier\n",
    "voxel_size = np.average(img_pve_wm.get_header()['pixdim'][1:4])\n",
    "step_size = 0.25\n",
    "\n",
    "cmc_classifier = CmcTissueClassifier.from_pve(img_pve_wm.get_data(),\n",
    "                                              img_pve_gm.get_data(),\n",
    "                                              img_pve_csf.get_data(),\n",
    "                                              step_size=step_size,\n",
    "                                              average_voxel_size=voxel_size)\n",
    "\n",
    "all_streamlines_cmc_classifier = LocalTracking(prob_dg,\n",
    "                                               cmc_classifier,\n",
    "                                               seeds, \n",
    "                                               affine=np.eye(4), step_size=0.75,\n",
    "                                               return_all=True)\n",
    "\n",
    "streamlines = Streamlines(all_streamlines_cmc_classifier)\n",
    "save_trk(\"prova_gqilinescript_oldmasks_oldodfs.trk\",\n",
    "         streamlines,\n",
    "         img.affine,\n",
    "         shape=img.shape[:3], vox_size=img.header.get_zooms()[:3])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Making Trackvis compatible ODFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphere181 = HemiSphere.from_sphere(get_sphere('symmetric362'))\n",
    "sphere362 = get_sphere('symmetric362')\n",
    "# sphere181.vertices = np.loadtxt('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/prova_flip/181dirtrackvis.txt', delimiter = ',')\n",
    "# l_values = np.sqrt(gtab.bvals * 0.01506)\n",
    "# tmp=np.tile(l_values, (3,1))\n",
    "# gradsT = gtab.bvecs.T\n",
    "# b_vector = gradsT * tmp\n",
    "# b_vector = b_vector.T\n",
    "gqi_vector = np.real(np.sinc(np.dot(b_vector, sphere362.vertices.T)* 1/np.pi))\n",
    "odfs = np.dot(data, gqi_vector)\n",
    "ijk = np.ascontiguousarray(np.array(np.nonzero(mask)).T)\n",
    "shape = data.shape[:-1]\n",
    "odfs_norm = np.zeros ((shape + (len(sphere362.vertices),)))\n",
    "\n",
    "for (k, center) in enumerate(ijk):\n",
    "    m = odfs[tuple(center.astype(np.int))].copy()\n",
    "    m = m - (np.abs(m).min())\n",
    "    m = m / (np.abs(m).max())\n",
    "    odfs_norm[tuple(center.astype(np.int))] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing\n",
    "interactive = True\n",
    "r = window.Renderer()\n",
    "\n",
    "gqi_odfs_181_actor = actor.odf_slicer(odfs_norm, sphere=sphere181, scale=0.6, norm=False, colormap= 'jet')\n",
    "r.add(gqi_odfs_181_actor)\n",
    "\n",
    "if interactive:\n",
    "    window.show(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting directions as first dimension and saving \n",
    "odfs_prova = np.transpose(odfs_norm, (1, 2, 3, 0))\n",
    "odfs_prova = np.transpose(odfs_prova, (1,2,3,0))\n",
    "odfs_prova = np.transpose(odfs_prova, (1,2,3,0))\n",
    "odfs_prova.shape\n",
    "nib.save(nib.Nifti1Image(odfs_prova.astype(np.float32),\n",
    "                                   img.affine, img.header), '/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/prova_flip/gqi_odfs_provatrackvis362.nii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere181.vertices = np.loadtxt('/space/hemera/1/users/cmaffei/scilpy_mrtrix_comparison/10000/from_mgh/prova_flip/181dirtrackvis.txt', delimiter = ',')\n",
    "faces_181 = faces_from_sphere_vertices(sphere181.vertices)\n",
    "edges_181 = unique_edges (faces_181)\n",
    "hemisphere_181 = HemiSphere(xyz=sphere181.vertices, faces= faces_181, edges=edges_181)\n",
    "sphere_181 = hemisphere_181.mirror()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
